/**
 * åˆ†æ®µ TTS å¤„ç†å·¥å…·
 * å°†é•¿æ–‡æœ¬åˆ†æ®µè¯·æ±‚ TTSï¼Œå®ç°å¿«é€Ÿå“åº”å’Œé¡ºåºæ’­æ”¾
 */

import { textToSpeech } from '@/service/module/agents'
import { createAudioToBlob } from '@/view/chat/utils/createAudio'
import indexedDBStorage from './indexedDBStorage'

/**
 * æ™ºèƒ½æ–‡æœ¬åˆ†æ®µ
 * @param {string} text - è¦åˆ†æ®µçš„æ–‡æœ¬
 * @param {number} maxChunkLength - æ¯æ®µæœ€å¤§é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰
 * @returns {string[]} åˆ†æ®µåçš„æ–‡æœ¬æ•°ç»„
 */
export function splitTextIntoChunks(text, maxChunkLength = 100) {
  if (!text || text.length <= maxChunkLength) {
    return [text]
  }

  const chunks = []
  const sentences = text.split(/([ã€‚ï¼ï¼Ÿï¼›.!?;])/g) // æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²ï¼Œä¿ç•™åˆ†éš”ç¬¦
  let currentChunk = ''

  for (let i = 0; i < sentences.length; i++) {
    const sentence = sentences[i]

    // å¦‚æœå½“å‰å—åŠ ä¸Šæ–°å¥å­ä¸è¶…è¿‡é™åˆ¶ï¼Œå°±æ·»åŠ 
    if ((currentChunk + sentence).length <= maxChunkLength) {
      currentChunk += sentence
    } else {
      // å¦‚æœå½“å‰å—ä¸ä¸ºç©ºï¼Œå…ˆä¿å­˜
      if (currentChunk.trim()) {
        chunks.push(currentChunk.trim())
      }
      // å¦‚æœå•ä¸ªå¥å­è¶…è¿‡é™åˆ¶ï¼Œå¼ºåˆ¶åˆ†å‰²
      if (sentence.length > maxChunkLength) {
        for (let j = 0; j < sentence.length; j += maxChunkLength) {
          chunks.push(sentence.slice(j, j + maxChunkLength))
        }
        currentChunk = ''
      } else {
        currentChunk = sentence
      }
    }
  }

  // æ·»åŠ æœ€åä¸€å—
  if (currentChunk.trim()) {
    chunks.push(currentChunk.trim())
  }

  return chunks.filter((chunk) => chunk.length > 0)
}

/**
 * åˆå¹¶å¤šä¸ªéŸ³é¢‘ Blob
 * @param {Blob[]} audioBlobs - éŸ³é¢‘ Blob æ•°ç»„
 * @returns {Promise<Blob>} åˆå¹¶åçš„éŸ³é¢‘ Blob
 */
export async function mergeAudioBlobs(audioBlobs) {
  if (audioBlobs.length === 0) {
    throw new Error('æ²¡æœ‰éŸ³é¢‘å¯åˆå¹¶')
  }

  if (audioBlobs.length === 1) {
    return audioBlobs[0]
  }

  try {
    // ä½¿ç”¨ AudioContext åˆå¹¶éŸ³é¢‘
    const audioContext = new (window.AudioContext || window.webkitAudioContext)()
    const audioBuffers = []

    // è§£ç æ‰€æœ‰éŸ³é¢‘
    for (const blob of audioBlobs) {
      const arrayBuffer = await blob.arrayBuffer()
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer)
      audioBuffers.push(audioBuffer)
    }

    // è®¡ç®—æ€»é•¿åº¦
    const totalLength = audioBuffers.reduce((sum, buffer) => sum + buffer.length, 0)
    const numberOfChannels = audioBuffers[0].numberOfChannels
    const sampleRate = audioBuffers[0].sampleRate

    // åˆ›å»ºåˆå¹¶åçš„ AudioBuffer
    const mergedBuffer = audioContext.createBuffer(numberOfChannels, totalLength, sampleRate)

    // å¤åˆ¶æ‰€æœ‰éŸ³é¢‘æ•°æ®
    let offset = 0
    for (const buffer of audioBuffers) {
      for (let channel = 0; channel < numberOfChannels; channel++) {
        mergedBuffer.getChannelData(channel).set(buffer.getChannelData(channel), offset)
      }
      offset += buffer.length
    }

    // å°† AudioBuffer è½¬æ¢ä¸º Blob
    const mergedBlob = await audioBufferToBlob(mergedBuffer, audioContext)
    audioContext.close()

    return mergedBlob
  } catch (error) {
    console.error('éŸ³é¢‘åˆå¹¶å¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ‹¼æ¥:', error)
    // å¦‚æœåˆå¹¶å¤±è´¥ï¼Œç®€å•æ‹¼æ¥ï¼ˆå¯èƒ½æœ‰é—´éš™ï¼‰
    return new Blob(audioBlobs, { type: 'audio/mp3' })
  }
}

/**
 * å°† AudioBuffer è½¬æ¢ä¸º Blob
 * @param {AudioBuffer} audioBuffer
 * @param {AudioContext} audioContext
 * @returns {Promise<Blob>}
 */
async function audioBufferToBlob(audioBuffer, audioContext) {
  return new Promise((resolve, reject) => {
    const offlineContext = new OfflineAudioContext(
      audioBuffer.numberOfChannels,
      audioBuffer.length,
      audioBuffer.sampleRate,
    )

    const source = offlineContext.createBufferSource()
    source.buffer = audioBuffer
    source.connect(offlineContext.destination)
    source.start()

    offlineContext
      .startRendering()
      .then((renderedBuffer) => {
        // è½¬æ¢ä¸º WAV æ ¼å¼
        const wav = audioBufferToWav(renderedBuffer)
        const blob = new Blob([wav], { type: 'audio/wav' })
        resolve(blob)
      })
      .catch(reject)
  })
}

/**
 * å°† AudioBuffer è½¬æ¢ä¸º WAV æ ¼å¼
 * @param {AudioBuffer} buffer
 * @returns {ArrayBuffer}
 */
function audioBufferToWav(buffer) {
  const length = buffer.length * buffer.numberOfChannels * 2 + 44
  const arrayBuffer = new ArrayBuffer(length)
  const view = new DataView(arrayBuffer)
  const channels = []
  let offset = 0
  let pos = 0

  // å†™å…¥ WAV å¤´
  const setUint16 = (data) => {
    view.setUint16(pos, data, true)
    pos += 2
  }
  const setUint32 = (data) => {
    view.setUint32(pos, data, true)
    pos += 4
  }

  // RIFF identifier
  setUint32(0x46464952)
  // file length
  setUint32(length - 8)
  // RIFF type
  setUint32(0x45564157)
  // format chunk identifier
  setUint32(0x20746d66)
  // format chunk length
  setUint32(16)
  // sample format (raw)
  setUint16(1)
  // channel count
  setUint16(buffer.numberOfChannels)
  // sample rate
  setUint32(buffer.sampleRate)
  // byte rate (sample rate * block align)
  setUint32(buffer.sampleRate * 2 * buffer.numberOfChannels)
  // block align (channel count * bytes per sample)
  setUint16(buffer.numberOfChannels * 2)
  // bits per sample
  setUint16(16)
  // data chunk identifier
  setUint32(0x61746164)
  // data chunk length
  setUint32(length - pos - 4)

  // å†™å…¥éŸ³é¢‘æ•°æ®
  for (let i = 0; i < buffer.numberOfChannels; i++) {
    channels.push(buffer.getChannelData(i))
  }

  while (pos < length) {
    for (let i = 0; i < buffer.numberOfChannels; i++) {
      let sample = Math.max(-1, Math.min(1, channels[i][offset]))
      sample = sample < 0 ? sample * 0x8000 : sample * 0x7fff
      view.setInt16(pos, sample, true)
      pos += 2
    }
    offset++
  }

  return arrayBuffer
}

/**
 * åˆ†æ®µ TTS å¤„ç†ç±»
 */
export class ChunkedTTSProcessor {
  constructor(config) {
    this.config = config // { voice, model, token }
    this.chunks = []
    this.audioBlobs = []
    this.currentPlayingIndex = 0
    this.audioElements = []
    this.isPlaying = false
    this.onChunkReady = null // å›è°ƒï¼šå½“æŸä¸ªåˆ†æ®µå‡†å¤‡å¥½æ—¶
    this.onAllComplete = null // å›è°ƒï¼šå½“æ‰€æœ‰åˆ†æ®µå®Œæˆæ—¶
    this.onError = null // å›è°ƒï¼šé”™è¯¯å¤„ç†
  }

  /**
   * å¤„ç†æ–‡æœ¬å¹¶å¼€å§‹ TTS
   * @param {string} text - å®Œæ•´æ–‡æœ¬
   * @param {number} chunkSize - æ¯æ®µå¤§å°
   */
  async process(text, chunkSize = 100) {
    this.chunks = splitTextIntoChunks(text, chunkSize)
    console.log(`ğŸ“ æ–‡æœ¬å·²åˆ†ä¸º ${this.chunks.length} æ®µ:`, this.chunks)

    // å¹¶è¡Œè¯·æ±‚æ‰€æœ‰åˆ†æ®µï¼ˆä½†é™åˆ¶å¹¶å‘æ•°ï¼‰
    const maxConcurrent = 3 // æœ€å¤šåŒæ—¶è¯·æ±‚ 3 ä¸ª
    const results = []

    for (let i = 0; i < this.chunks.length; i += maxConcurrent) {
      const batch = this.chunks.slice(i, i + maxConcurrent)
      const batchPromises = batch.map((chunk, batchIndex) => this.requestTTS(chunk, i + batchIndex))

      const batchResults = await Promise.allSettled(batchPromises)
      results.push(...batchResults)
    }

    // æ£€æŸ¥æ˜¯å¦æœ‰å¤±è´¥çš„è¯·æ±‚
    const failedCount = results.filter((r) => r.status === 'rejected').length
    if (failedCount > 0) {
      console.warn(`âš ï¸ ${failedCount} ä¸ªåˆ†æ®µè¯·æ±‚å¤±è´¥`)
    }

    // åˆå¹¶æ‰€æœ‰æˆåŠŸçš„éŸ³é¢‘
    const successfulBlobs = results.filter((r) => r.status === 'fulfilled').map((r) => r.value)

    if (successfulBlobs.length === 0) {
      throw new Error('æ‰€æœ‰ TTS è¯·æ±‚éƒ½å¤±è´¥äº†')
    }

    console.log('ğŸµ å¼€å§‹åˆå¹¶éŸ³é¢‘...')
    const mergedBlob = await mergeAudioBlobs(successfulBlobs)
    console.log('âœ… éŸ³é¢‘åˆå¹¶å®Œæˆ')

    if (this.onAllComplete) {
      this.onAllComplete(mergedBlob, successfulBlobs)
    }

    return {
      mergedBlob,
      chunks: successfulBlobs,
      totalChunks: this.chunks.length,
      successCount: successfulBlobs.length,
    }
  }

  /**
   * è¯·æ±‚å•ä¸ªåˆ†æ®µçš„ TTS
   * @param {string} chunk - æ–‡æœ¬åˆ†æ®µ
   * @param {number} index - åˆ†æ®µç´¢å¼•
   */
  async requestTTS(chunk, index) {
    try {
      console.log(`ğŸ¤ è¯·æ±‚ç¬¬ ${index + 1} æ®µ TTS: "${chunk.substring(0, 20)}..."`)

      const targetConfig = {
        input: chunk,
        gain: 0,
        model: this.config.model,
        speed: 1.15,
        response_format: 'mp3',
        voice: this.config.voice,
      }

      const response = await textToSpeech(targetConfig, this.config.token)
      const [audioElem, audioBlob] = await createAudioToBlob(response)

      this.audioBlobs[index] = audioBlob
      this.audioElements[index] = audioElem

      console.log(`âœ… ç¬¬ ${index + 1} æ®µå®Œæˆ`)

      // å¦‚æœæ˜¯ç¬¬ä¸€æ®µï¼Œç«‹å³é€šçŸ¥å¯ä»¥æ’­æ”¾
      if (index === 0 && this.onChunkReady) {
        this.onChunkReady(audioElem, audioBlob, index)
      }

      return audioBlob
    } catch (error) {
      console.error(`âŒ ç¬¬ ${index + 1} æ®µå¤±è´¥:`, error)
      if (this.onError) {
        this.onError(error, index)
      }
      throw error
    }
  }

  /**
   * é¡ºåºæ’­æ”¾æ‰€æœ‰åˆ†æ®µ
   */
  async playSequentially() {
    if (this.isPlaying) return
    this.isPlaying = true

    for (let i = 0; i < this.audioElements.length; i++) {
      if (this.audioElements[i]) {
        await this.playAudio(this.audioElements[i], i)
      }
    }

    this.isPlaying = false
  }

  /**
   * æ’­æ”¾å•ä¸ªéŸ³é¢‘
   */
  playAudio(audioElem, index) {
    return new Promise((resolve) => {
      console.log(`â–¶ï¸ æ’­æ”¾ç¬¬ ${index + 1} æ®µ`)

      audioElem.addEventListener(
        'ended',
        () => {
          console.log(`â¹ï¸ ç¬¬ ${index + 1} æ®µæ’­æ”¾å®Œæˆ`)
          resolve()
        },
        { once: true },
      )

      audioElem.addEventListener(
        'error',
        (e) => {
          console.error(`âŒ ç¬¬ ${index + 1} æ®µæ’­æ”¾é”™è¯¯:`, e)
          resolve() // ç»§ç»­æ’­æ”¾ä¸‹ä¸€æ®µ
        },
        { once: true },
      )

      audioElem.play().catch((err) => {
        console.error(`âŒ æ’­æ”¾å¤±è´¥:`, err)
        resolve()
      })
    })
  }

  /**
   * åœæ­¢æ’­æ”¾
   */
  stop() {
    this.isPlaying = false
    this.audioElements.forEach((elem) => {
      if (elem) {
        elem.pause()
        elem.currentTime = 0
      }
    })
  }

  /**
   * æ¸…ç†èµ„æº
   */
  cleanup() {
    this.stop()
    this.audioElements.forEach((elem) => {
      if (elem && elem.parentNode) {
        elem.parentNode.removeChild(elem)
      }
    })
    this.audioElements = []
    this.audioBlobs = []
  }
}

/**
 * ä¾¿æ·å‡½æ•°ï¼šåˆ†æ®µ TTS å¹¶ä¿å­˜åˆ° IndexedDB
 * @param {string} text - æ–‡æœ¬
 * @param {string} userName - ç”¨æˆ·å
 * @param {object} ttsConfig - TTS é…ç½® { voice, model, token }
 * @param {number} chunkSize - åˆ†æ®µå¤§å°
 * @returns {Promise<object>} { audioElem, messageId, audioBlob }
 */
export async function chunkedTTSWithStorage(text, userName, ttsConfig, chunkSize = 100) {
  const processor = new ChunkedTTSProcessor(ttsConfig)

  // å¤„ç†å¹¶è·å–åˆå¹¶åçš„éŸ³é¢‘
  const result = await processor.process(text, chunkSize)

  // åˆ›å»ºéŸ³é¢‘å…ƒç´ 
  const audioUrl = URL.createObjectURL(result.mergedBlob)
  const audioElem = document.createElement('audio')
  audioElem.src = audioUrl
  document.body.appendChild(audioElem)

  // ä¿å­˜åˆ° IndexedDB
  const messageId = `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
  try {
    await indexedDBStorage.saveAudioMessage(userName, messageId, result.mergedBlob, text)
    console.log('âœ… åˆå¹¶éŸ³é¢‘å·²ä¿å­˜åˆ° IndexedDB:', messageId)
  } catch (error) {
    console.warn('âš ï¸ ä¿å­˜éŸ³é¢‘åˆ° IndexedDB å¤±è´¥:', error)
  }

  // æ¸…ç†èµ„æº
  processor.cleanup()

  return {
    audioElem,
    messageId,
    audioBlob: result.mergedBlob,
    chunks: result.chunks,
    stats: {
      totalChunks: result.totalChunks,
      successCount: result.successCount,
    },
  }
}
